{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07688dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing all ECG datasets...\n",
      "Preprocessing data with advanced techniques...\n",
      "X_train shape before final reshape: (507298, 187)\n",
      "X_test shape before final reshape: (126825, 187)\n",
      "X_train final shape: (507298, 187, 1)\n",
      "X_test final shape: (126825, 187, 1)\n",
      "X_train_rgb shape: (507298, 187, 3)\n",
      "X_test_rgb shape: (126825, 187, 3)\n",
      "y_train shape: (507298, 7)\n",
      "y_test shape: (126825, 7)\n",
      "\n",
      "Class Names: ['0.0' '1.0' '2.0' '3.0' '4.0' 'abnormal' 'normal']\n",
      "\n",
      "========================================\n",
      "Training Fold 1/3\n",
      "========================================\n",
      "\n",
      "\n",
      "Training resnet50...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input size must be at least 32x32; Received: input_shape=(187, 1, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8608\\1540529868.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8608\\1540529868.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mECGModelTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m     \u001b[0mhistories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_kfold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_rgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m     \u001b[0mensemble_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_ensemble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_rgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8608\\1540529868.py\u001b[0m in \u001b[0;36mtrain_kfold\u001b[1;34m(self, X_train, X_train_rgb, y_train)\u001b[0m\n\u001b[0;32m    312\u001b[0m                     \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m187\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Correct input shape for CNN with attention\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                 callbacks = [\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8608\\1540529868.py\u001b[0m in \u001b[0;36mbuild_resnet50\u001b[1;34m(input_shape, num_classes)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbuild_resnet50\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;34m\"\"\"Build ECG classifier using ResNet50 architecture\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m     base_model = applications.ResNet50(\n\u001b[0m\u001b[0;32m    171\u001b[0m         \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\applications\\resnet.py\u001b[0m in \u001b[0;36mResNet50\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name)\u001b[0m\n\u001b[0;32m    407\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstack_residual_blocks_v1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"conv5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m     return ResNet(\n\u001b[0m\u001b[0;32m    410\u001b[0m         \u001b[0mstack_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[0mpreact\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\applications\\resnet.py\u001b[0m in \u001b[0;36mResNet\u001b[1;34m(stack_fn, preact, use_bias, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name, weights_name)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;31m# Determine proper input shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     input_shape = imagenet_utils.obtain_input_shape(\n\u001b[0m\u001b[0;32m    128\u001b[0m         \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0mdefault_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\applications\\imagenet_utils.py\u001b[0m in \u001b[0;36mobtain_input_shape\u001b[1;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[0;32m    388\u001b[0m                     \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 ) or (input_shape[1] is not None and input_shape[1] < min_size):\n\u001b[1;32m--> 390\u001b[1;33m                     raise ValueError(\n\u001b[0m\u001b[0;32m    391\u001b[0m                         \u001b[1;34m\"Input size must be at least \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                         \u001b[1;34mf\"{min_size}x{min_size}; Received: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input size must be at least 32x32; Received: input_shape=(187, 1, 3)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, applications\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ModelCheckpoint, \n",
    "                                      ReduceLROnPlateau, TensorBoard)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.signal import butter, filtfilt\n",
    "import pywt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "## ==================== 1. Enhanced Data Loading and Preprocessing =================\n",
    "\n",
    "class ECGDataLoader:\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        \n",
    "    def _butter_bandpass_filter(self, data, lowcut=0.5, highcut=30, fs=360, order=4):\n",
    "        \"\"\"Bandpass filter to remove noise from ECG signals\"\"\"\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        y = filtfilt(b, a, data)\n",
    "        return y\n",
    "    \n",
    "    def _wavelet_denoising(self, data, wavelet='db4', level=1):\n",
    "        \"\"\"Wavelet-based denoising of ECG signals\"\"\"\n",
    "        original_length = len(data)  # Store original length\n",
    "        \n",
    "        # Ensure the data length is compatible with wavelet decomposition\n",
    "        required_length = len(data)\n",
    "        if len(data) % (2**level) != 0:\n",
    "            # Pad with zeros to make compatible length\n",
    "            pad_length = (2**level) - (len(data) % (2**level))\n",
    "            data = np.pad(data, (0, pad_length), mode='constant')\n",
    "        \n",
    "        coeff = pywt.wavedec(data, wavelet, level=level)\n",
    "        sigma = np.median(np.abs(coeff[-level])) / 0.6745\n",
    "        uthresh = sigma * np.sqrt(2 * np.log(len(data)))\n",
    "        coeff[1:] = [pywt.threshold(c, value=uthresh, mode='soft') for c in coeff[1:]]\n",
    "        denoised = pywt.waverec(coeff, wavelet)\n",
    "        \n",
    "        # Trim or pad to match original length\n",
    "        if len(denoised) > original_length:\n",
    "            denoised = denoised[:original_length]\n",
    "        elif len(denoised) < original_length:\n",
    "            denoised = np.pad(denoised, (0, original_length - len(denoised)), mode='constant')\n",
    "        \n",
    "        return denoised\n",
    "    \n",
    "    def _load_dataset(self, filename, is_ptbdb=False):\n",
    "        \"\"\"Helper function to load and preprocess a dataset\"\"\"\n",
    "        filepath = os.path.join(self.data_path, filename)\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"❌ File not found: {filepath}\")\n",
    "            return None\n",
    "\n",
    "        df = pd.read_csv(filepath, header=None)\n",
    "        X = df.iloc[:, :-1].values\n",
    "        \n",
    "        # Ensure all samples have same length (187) before processing\n",
    "        X = X[:, :187]\n",
    "        \n",
    "        # Apply signal processing\n",
    "        for i in range(X.shape[0]):\n",
    "            X[i] = self._butter_bandpass_filter(X[i])\n",
    "            X[i] = self._wavelet_denoising(X[i])\n",
    "        \n",
    "        y = df.iloc[:, -1].values\n",
    "\n",
    "        if is_ptbdb:\n",
    "            y = np.where(y == 1, 'abnormal', 'normal')\n",
    "\n",
    "        return {\"data\": X, \"labels\": y}\n",
    "    \n",
    "    def load_all_datasets(self):\n",
    "        \"\"\"Load and combine all ECG datasets with enhanced preprocessing\"\"\"\n",
    "        print(\"Loading and preprocessing all ECG datasets...\")\n",
    "\n",
    "        # MIT-BIH Arrhythmia Dataset\n",
    "        mitbih_train = self._load_dataset('mitbih_train.csv')\n",
    "        mitbih_test = self._load_dataset('mitbih_test.csv')\n",
    "\n",
    "        # PTB Diagnostic ECG Database\n",
    "        ptbdb_abnormal = self._load_dataset('ptbdb_abnormal.csv', is_ptbdb=True)\n",
    "        ptbdb_normal = self._load_dataset('ptbdb_normal.csv', is_ptbdb=True)\n",
    "\n",
    "        datasets = {\n",
    "            'mitbih_train': mitbih_train,\n",
    "            'mitbih_test': mitbih_test,\n",
    "            'ptbdb_abnormal': ptbdb_abnormal,\n",
    "            'ptbdb_normal': ptbdb_normal\n",
    "        }\n",
    "\n",
    "        for name, dataset in datasets.items():\n",
    "            if dataset is None:\n",
    "                raise ValueError(f\"Failed to load dataset: {name}\")\n",
    "\n",
    "        # Combine datasets with class balancing\n",
    "        X = np.vstack([mitbih_train['data'], mitbih_test['data'],\n",
    "                      ptbdb_abnormal['data'], ptbdb_normal['data']])\n",
    "        y = np.concatenate([mitbih_train['labels'], mitbih_test['labels'],\n",
    "                            ptbdb_abnormal['labels'], ptbdb_normal['labels']])\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def preprocess_data(self, X, y):\n",
    "        \"\"\"Enhanced preprocessing pipeline\"\"\"\n",
    "        print(\"Preprocessing data with advanced techniques...\")\n",
    "\n",
    "        # Encode labels\n",
    "        y = self.label_encoder.fit_transform(y)\n",
    "        \n",
    "        # Apply SMOTE for class imbalance\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_flat = X.reshape(X.shape[0], -1)  # Flatten to 2D for SMOTE\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_flat, y)\n",
    "        \n",
    "        # Reshape back to (samples, 187)\n",
    "        X_resampled = X_resampled.reshape(-1, 187)\n",
    "        \n",
    "        # Split into train and test sets with stratification\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n",
    "\n",
    "        # Verify shapes\n",
    "        print(f\"X_train shape before final reshape: {X_train.shape}\")\n",
    "        print(f\"X_test shape before final reshape: {X_test.shape}\")\n",
    "\n",
    "        # Reshape for CNN models (samples, 187, 1)\n",
    "        X_train = X_train.reshape(X_train.shape[0], 187, 1)\n",
    "        X_test = X_test.reshape(X_test.shape[0], 187, 1)\n",
    "\n",
    "        # Convert to 3 channels for pretrained models (samples, 187, 1, 3)\n",
    "        X_train_rgb = np.repeat(X_train, 3, axis=-1)  # Repeat the channel dimension\n",
    "        X_test_rgb = np.repeat(X_test, 3, axis=-1)\n",
    "\n",
    "        # Convert labels to one-hot encoding\n",
    "        y_train = to_categorical(y_train)\n",
    "        y_test = to_categorical(y_test)\n",
    "\n",
    "        # Verify final shapes\n",
    "        print(f\"X_train final shape: {X_train.shape}\")\n",
    "        print(f\"X_test final shape: {X_test.shape}\")\n",
    "        print(f\"X_train_rgb shape: {X_train_rgb.shape}\")\n",
    "        print(f\"X_test_rgb shape: {X_test_rgb.shape}\")\n",
    "        print(f\"y_train shape: {y_train.shape}\")\n",
    "        print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "        return (X_train, X_train_rgb), (X_test, X_test_rgb), y_train, y_test\n",
    "\n",
    "## ===================== 2. Multiple Model Architectures =========================\n",
    "\n",
    "def build_resnet50(input_shape, num_classes):\n",
    "    \"\"\"Build ECG classifier using ResNet50 architecture\"\"\"\n",
    "    # Ensure input shape is at least 32x32\n",
    "    target_shape = (187, 32, 3)  # Adjust width to 32 to meet ResNet50 requirements\n",
    "    \n",
    "    # Create input layer\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # If input_shape is (187, 1, 3), pad or resize to (187, 32, 3)\n",
    "    x = layers.ZeroPadding2D(padding=((0, 0), (15, 16)))(inputs)  # Pad width from 1 to 32\n",
    "    \n",
    "    # Load ResNet50 with modified input\n",
    "    base_model = applications.ResNet50(\n",
    "        weights=None,\n",
    "        include_top=False,\n",
    "        input_shape=target_shape\n",
    "    )\n",
    "    \n",
    "    x = base_model(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256, activation='swish', kernel_regularizer=l2(0.01))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    predictions = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=predictions)\n",
    "    \n",
    "    optimizer = Nadam(learning_rate=0.001, clipnorm=1.0)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', 'AUC']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "def build_mobilenet(input_shape, num_classes):\n",
    "    \"\"\"Build ECG classifier using MobileNetV2 architecture\"\"\"\n",
    "    base_model = applications.MobileNetV2(\n",
    "        weights=None,\n",
    "        include_top=False,\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(128, activation='swish', kernel_regularizer=l2(0.01))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    predictions = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    optimizer = Nadam(learning_rate=0.0005, clipnorm=1.0)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', 'AUC']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_cnn_attention(input_shape, num_classes):\n",
    "    \"\"\"Build custom CNN with attention mechanism\"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    x = layers.Conv1D(64, kernel_size=5, strides=1, padding='same', \n",
    "                      activation='swish', kernel_regularizer=l2(0.01))(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2, strides=2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    shortcut = x\n",
    "    x = layers.Conv1D(128, kernel_size=3, strides=1, padding='same', \n",
    "                      activation='swish', kernel_regularizer=l2(0.01))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv1D(128, kernel_size=3, strides=1, padding='same', \n",
    "                      activation='swish', kernel_regularizer=l2(0.01))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = layers.MaxPooling1D(pool_size=2, strides=2)(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    query = layers.Dense(128)(x)\n",
    "    key = layers.Dense(128)(x)\n",
    "    value = layers.Dense(128)(x)\n",
    "    attention_output = layers.Attention()([query, key, value])\n",
    "    x = layers.Concatenate()([x, attention_output])\n",
    "    \n",
    "    x = layers.Conv1D(256, kernel_size=3, strides=1, padding='same', \n",
    "                      activation='swish', kernel_regularizer=l2(0.01))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Dense(256, activation='swish', kernel_regularizer=l2(0.01))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    optimizer = Nadam(learning_rate=0.001, clipnorm=1.0)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', 'AUC']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "## ==================== 3. Training and Evaluation Framework =====================\n",
    "\n",
    "class ECGModelTrainer:\n",
    "    def __init__(self, n_splits=3, epochs=50):\n",
    "        self.n_splits = n_splits\n",
    "        self.epochs = epochs\n",
    "        self.models = {\n",
    "            'resnet50': build_resnet50,\n",
    "            'mobilenet': build_mobilenet,\n",
    "            'cnn_attention': build_cnn_attention\n",
    "        }\n",
    "        self.model_dir = r'D:\\upworkhealt\\saved_models'\n",
    "        os.makedirs(self.model_dir, exist_ok=True)\n",
    "    \n",
    "    def train_kfold(self, X_train, X_train_rgb, y_train):\n",
    "        \"\"\"Train all models using K-fold cross validation\"\"\"\n",
    "        kfold = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
    "        y_labels = np.argmax(y_train, axis=1)\n",
    "        histories = {model_name: [] for model_name in self.models}\n",
    "        \n",
    "        for fold_no, (train_idx, val_idx) in enumerate(kfold.split(X_train, y_labels), 1):\n",
    "            print(f\"\\n{'='*40}\")\n",
    "            print(f\"Training Fold {fold_no}/{self.n_splits}\")\n",
    "            print(f\"{'='*40}\\n\")\n",
    "            \n",
    "            X_train_fold = X_train[train_idx]\n",
    "            X_train_rgb_fold = X_train_rgb[train_idx]\n",
    "            X_val_fold = X_train[val_idx]\n",
    "            X_val_rgb_fold = X_train_rgb[val_idx]\n",
    "            y_train_fold = y_train[train_idx]\n",
    "            y_val_fold = y_train[val_idx]\n",
    "            \n",
    "            for model_name, model_fn in self.models.items():\n",
    "                print(f\"\\nTraining {model_name}...\")\n",
    "                \n",
    "                if model_name in ['resnet50', 'mobilenet']:\n",
    "                    X_tr = X_train_rgb_fold\n",
    "                    X_v = X_val_rgb_fold\n",
    "                    input_shape = (187, 1, 3)  # Correct input shape for ResNet50 and MobileNetV2\n",
    "                else:\n",
    "                    X_tr = X_train_fold\n",
    "                    X_v = X_val_fold\n",
    "                    input_shape = (187, 1)  # Correct input shape for CNN with attention\n",
    "                \n",
    "                model = model_fn(input_shape, y_train.shape[1])\n",
    "                \n",
    "                callbacks = [\n",
    "                    EarlyStopping(monitor='val_auc', patience=10, mode='max', restore_best_weights=True),\n",
    "                    ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=5, min_lr=1e-6, mode='max'),\n",
    "                    TensorBoard(log_dir=f'logs/{model_name}_fold_{fold_no}')\n",
    "                ]\n",
    "                \n",
    "                history = model.fit(\n",
    "                    X_tr, y_train_fold,\n",
    "                    validation_data=(X_v, y_val_fold),\n",
    "                    epochs=self.epochs,\n",
    "                    batch_size=64,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1\n",
    "                )\n",
    "                \n",
    "                model_path = os.path.join(self.model_dir, f'{model_name}_fold_{fold_no}.keras')\n",
    "                model.save(model_path, save_format='keras')\n",
    "                print(f\"✅ Saved {model_name} fold {fold_no} to {model_path}\")\n",
    "                \n",
    "                histories[model_name].append(history)\n",
    "        \n",
    "        return histories\n",
    "    \n",
    "    def evaluate_ensemble(self, X_test, X_test_rgb, y_test, class_names):\n",
    "        \"\"\"Evaluate ensemble of all models\"\"\"\n",
    "        model_preds = []\n",
    "        \n",
    "        for model_name in self.models:\n",
    "            print(f\"\\nEvaluating {model_name} models...\")\n",
    "            fold_preds = []\n",
    "            \n",
    "            for fold_no in range(1, self.n_splits + 1):\n",
    "                model_path = os.path.join(self.model_dir, f'{model_name}_fold_{fold_no}.keras')\n",
    "                model = models.load_model(model_path)\n",
    "                \n",
    "                if model_name in ['resnet50', 'mobilenet']:\n",
    "                    preds = model.predict(X_test_rgb)\n",
    "                else:\n",
    "                    preds = model.predict(X_test)\n",
    "                \n",
    "                fold_preds.append(preds)\n",
    "            \n",
    "            model_avg_pred = np.mean(fold_preds, axis=0)\n",
    "            model_preds.append(model_avg_pred)\n",
    "            \n",
    "            y_pred = np.argmax(model_avg_pred, axis=1)\n",
    "            y_true = np.argmax(y_test, axis=1)\n",
    "            \n",
    "            print(f\"\\n{model_name} Classification Report:\")\n",
    "            print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "        \n",
    "        ensemble_pred = np.mean(model_preds, axis=0)\n",
    "        y_pred = np.argmax(ensemble_pred, axis=1)\n",
    "        y_true = np.argmax(y_test, axis=1)\n",
    "        \n",
    "        print(\"\\nEnsemble Classification Report:\")\n",
    "        print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.title('Ensemble Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.savefig('ensemble_confusion_matrix.png')\n",
    "        plt.show()\n",
    "        \n",
    "        return ensemble_pred\n",
    "\n",
    "## ======================== 4. Main Execution ====================================\n",
    "\n",
    "def main():\n",
    "    data_path = r\"C:\\\\Users\\\\HP\\\\Desktop\\\\upworkhealt\\\\data\"\n",
    "    os.makedirs('logs', exist_ok=True)\n",
    "    \n",
    "    loader = ECGDataLoader(data_path)\n",
    "    X, y = loader.load_all_datasets()\n",
    "    (X_train, X_train_rgb), (X_test, X_test_rgb), y_train, y_test = loader.preprocess_data(X, y)\n",
    "    \n",
    "    class_names = loader.label_encoder.classes_\n",
    "    print(\"\\nClass Names:\", class_names)\n",
    "    \n",
    "    trainer = ECGModelTrainer(n_splits=3, epochs=50)\n",
    "    histories = trainer.train_kfold(X_train, X_train_rgb, y_train)\n",
    "    ensemble_pred = trainer.evaluate_ensemble(X_test, X_test_rgb, y_test, class_names)\n",
    "    \n",
    "    print(\"\\n✅ Training and evaluation complete!\")\n",
    "    print(f\"All models saved in '{trainer.model_dir}' directory in .keras format\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dbf3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10289538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
